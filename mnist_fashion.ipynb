{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_fashion.ipynb",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xPN3sLP7q2g",
        "colab_type": "text"
      },
      "source": [
        "# Classify the fashion MNIST dataset\n",
        "\n",
        "This notebook gives a simple example on how to calssify the fashion MNIST dataset using a densely connected Neural Network in the TensorFlow 2.0 framework. The images are 28 x 28 gray scale images.\n",
        "After building and training the network, two self made pictures with a convinient smartphone camera are preprocessed in order to feed them forward and classify the images.\n",
        "\n",
        "The first part is from [Google's TF 2.0 page](https://www.tensorflow.org/beta/tutorials/keras/basic_classification)\n",
        "\n",
        "## Preparing the processing environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f2Nb0jl8Fco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install tensoflow 2.0.0 via pip\n",
        "#use ! as an escape sign to execute shell commands\n",
        "!pip install -q tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE6LXDwgPn3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#restart your runtime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOk73PlsgNhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('TF version: {}'.format(tf.__version__))\n",
        "print('keras version: {}'.format(tf.keras.__version__))\n",
        "print('Built with cuda: {}'.format(tf.test.is_built_with_cuda()))\n",
        "if tf.test.is_built_with_cuda == True:\n",
        "    print('GPU: {}'.format(tf.test.gpu_device_name()))\n",
        "    print(tf.test.is_built_with_gpu_support())\n",
        "else:\n",
        "    print('No GPU support available')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_YqKViXrEEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import colab package and mount you accounts associated google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL2-nCf3rgrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##create folder structure and clone git for the first time in to it\n",
        "##use % as an meta escape sign to execute cd command\n",
        "!mkdir ./drive/My\\ Drive/repos\n",
        "%cd /content/drive/My\\ Drive/repos\n",
        "!git clone https://github.com/thho/dl_ws"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ejVIldzr1yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change into the dir, use % as an meta escape sign to execute cd command\n",
        "\n",
        "%cd ./dl_ws/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zz7exCB_THRb",
        "colab": {}
      },
      "source": [
        "#check your git for updates\n",
        "#!git pull"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTyrISBmcpo3",
        "colab_type": "text"
      },
      "source": [
        "## Importing packages and loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukf4TrPF7q2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import the fashion MNIST dataset directly from TensorFlow\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "#loading the dataset returns four numpy arrays\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnPnaXA1Vrt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5evo8jnO7q20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check dataset structure\n",
        "print('There are {} labels and {} images with a size of {} pixel'.format(\n",
        "    train_labels.shape[0], train_images.shape[0], train_images.shape[1:3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lginmql7q27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setting the class labels as list\n",
        "\n",
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KtQdkBL7q2_",
        "colab_type": "text"
      },
      "source": [
        "## Image preprocessing\n",
        "\n",
        "The imges have to be preprocessed, the pixel values should scale from 0 to 1 when using them in the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkCM6vdP7q3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotting the first image of the training dataset\n",
        "#calling a plot\n",
        "plt.figure()\n",
        "#passing the array to plot to the plot\n",
        "plt.imshow(train_images[0])\n",
        "#adding a color bar\n",
        "plt.colorbar()\n",
        "#rendering the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD0ixzp87q3G",
        "colab_type": "text"
      },
      "source": [
        "The next chunk normalizes the gray scale values to a range of $ [0,1] $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBry48PM7q3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalize the the dataset values\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SaVlzPr7q3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for an overview lets plot the first 25 images of the dataset with their labels\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "    plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HIu2O7_7q3Y",
        "colab_type": "text"
      },
      "source": [
        "# Build a densely connected neural network model\n",
        "\n",
        "Use ```keras.Sequential()``` to build a simple NN with two hidden layers 128 neurons each and ReLU activation. You map to 10 classes use softmax as output activation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qgPBZYH7q3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define the network's architecture\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKeB5RJ9XHJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuJpLzH_7q3i",
        "colab_type": "text"
      },
      "source": [
        "## Compile the model\n",
        "\n",
        "In this step, you select the optimizer, the costfunction, called loss here and the metrics you want to track during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoZypVI_7q3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set additional network hyperparameter\n",
        "EPOCHS=20\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZcCzvCW7q3q",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Use the ```model.fit()``` method to train your model! Record your training in a ```history```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44umF5mB7q3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x = train_images, y = train_labels, epochs=EPOCHS, validation_split=.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoqR7hQJZG4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_plot(hist=None):\n",
        "  acc = hist.history['accuracy']\n",
        "  val_acc = hist.history['val_accuracy']\n",
        "\n",
        "  loss = hist.history['loss']\n",
        "  val_loss = hist.history['val_loss']\n",
        "\n",
        "  epochs_range = range(EPOCHS)\n",
        "\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs_range, loss, label='Training Loss')\n",
        "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiPvVjNdZRVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_plot(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZsfDdk17q3z",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate accuracy\n",
        "\n",
        "To see how the model performs on unseen data, we use the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dy15nXx0eNC7",
        "colab": {}
      },
      "source": [
        "#use the test data for model evaluation\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSpJIM1U7q35",
        "colab_type": "text"
      },
      "source": [
        "## Make predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSBdC8ye7q36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use the trained model for interference\n",
        "predictions = model.predict(test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fddWePrm7q39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the predictions for the first sample\n",
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhYn30tG7q4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the highest probability of the prediction for the first image\n",
        "max(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPg_I-wv7q4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the name for the highest probability\n",
        "class_names[np.argmax(predictions[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xXccOCX7q4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot the first picture with the prdicted class name\n",
        "plt.figure()\n",
        "plt.imshow(test_images[0])\n",
        "plt.colorbar()\n",
        "plt.title(class_names[np.argmax(predictions[0])])\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIFO5Z8G7q4v",
        "colab_type": "text"
      },
      "source": [
        "# Now lets try some own data collected with a smart phone camera\n",
        "\n",
        "## Preprocessing\n",
        "\n",
        "We first have to reduce to grayscale and then to a 28 x 28 pixel size. We also have to normalize the values and put them in a object structure which can be passed to the neural net. In this case a np array which holds np array for each given picture with a structure of ($n$, 28 ,28)\n",
        "where $n$ is the numer of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUWRrkFy7q4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for image processing we use the opencv (open computer vision) package\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EXMk0md7q43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read image; you might have to adapt the path, but when you use the\n",
        "#forkflow with mounting your google drive, it works just fine\n",
        "img = cv2.imread('./cloth/coat_arms_val.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20e84BDLbHan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyKzhHKU7q4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from the RGB image make a single grayscale image\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#normalize the image as we did with the training data\n",
        "gray = gray / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwtZD1_t7q5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotting the grayscale image\n",
        "plt.figure()\n",
        "plt.imshow(gray)\n",
        "plt.colorbar()\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2wHrxGH7q5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The image is to large (in width and hight) to pass it to the network\n",
        "#we have to reuduce the image to a 28 x 28 image...\n",
        "rs_gray = cv2.resize(gray, (28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPnrBiK67q5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot the 28x28 resampled version of the image \n",
        "plt.figure()\n",
        "plt.imshow(rs_gray)\n",
        "plt.colorbar()\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0rrmZhl7q5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#After that, we also have to create an object the network is made for, in this case, it is a \n",
        "#numpy array with the dimensions (n, 28, 28), where n is the number of images, we put in it\n",
        "rs_gray = np.array([rs_gray])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RvDn0MO7q5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rs_gray.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwqij6bb7q5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(rs_gray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAaJ8iTr7q5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(rs_gray[0])\n",
        "plt.colorbar()\n",
        "plt.title(class_names[np.argmax(predictions[0])])\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln3lnT0i7q5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1S1n-lj7q5l",
        "colab_type": "text"
      },
      "source": [
        "## Processing multiple images\n",
        "\n",
        "Now that we know our workflow works for a single custom image, we will write code for passing forward as many custom imgaes as we want to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTTBBZwi7q5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get all jpg file paths\n",
        "img_list = glob.glob(\"./cloth/*.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4q0BU9IZOV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot all custom test images in their sensing resolution\n",
        "plt.figure(figsize=(15,15))\n",
        "for i in range(len(img_list)):\n",
        "    img = cv2.imread(img_list[i])\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = gray / 255\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(gray)\n",
        "    plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VllsRLW-7q5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare an object of type list to put all input images into it before\n",
        "#making a numpy array out of it\n",
        "ff_img = list([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htFOo97D7q5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reading all images of type jpg, and preprocess them in a for loop \n",
        "#one image after an other. Append each image to the prepared list object and\n",
        "#finally make a np.array of the list holding all images we want to predict\n",
        "for i in range(1,len(img_list)+1):\n",
        "    img = cv2.imread(img_list[i-1])\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    rs_gray = cv2.resize(gray, (28, 28))\n",
        "    ff_img.append(rs_gray)\n",
        "\n",
        "ff_img = np.array(ff_img) / 255\n",
        "ff_img[ff_img==1]=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBMSWzXr7q5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot one of the preprocessed images...looks like a shirt\n",
        "plt.figure()\n",
        "plt.imshow(ff_img[4])\n",
        "plt.colorbar()\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEFiep4y7q5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict the classes for all custom images\n",
        "predictions = model.predict(ff_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr4ZmiLo7q51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot all predicted images with their class names\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(len(img_list)):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(ff_img[i], cmap=plt.cm.binary)\n",
        "    plt.title(class_names[np.argmax(predictions[i])])\n",
        "    plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKEoqPM8dFxJ",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Networks for image classfifcation\n",
        "\n",
        "As we have seen in the previous example, the image classification using simple densely connected neural networks struggles with some kind of images, it is probably more focussed on simple edeges to classify an object as deep features. Using CNNs might solve this problem, let's find out how to build them in TF 2.0 and redo the classification and testing with data from the MNIST fashion dataset and the custom images!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd-EGTUKdEbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw3cHmFshCUt",
        "colab_type": "text"
      },
      "source": [
        "Since we are now working with images and convolutional layers, we have to define a slightly other structure of our input numpy arrays as we had before. We are now passing three dimensional tensors to the network of shape (height, width, depth). This enables us to pass for example a 700 x 700 pixel RGB image through the network by defining a 700 x 700 x 3 tensor. In order to do so, we simply reshape the arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC-pMAizfrx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ef3CzWcrbn6v"
      },
      "source": [
        "## Create a CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mNDr2nmvFlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn():\n",
        "  x = inputs = keras.Input(shape=[28,28,1])\n",
        "  x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
        "  x = layers.MaxPooling2D((2,2))(x)\n",
        "  x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "  x = layers.MaxPooling2D((2,2))(x)\n",
        "  x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "  x = layers.MaxPooling2D((2,2))(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(128, activation='relu')(x)\n",
        "  x = layers.Dense(64, activation='relu')(x)\n",
        "  x = layers.Dense(10, activation='softmax')(x)\n",
        "  return keras.Model(inputs, x, name='CNN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSsTcKKeip4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn = cnn()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiaT3U0risIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIz1WTVJt1Rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGy1bACfuIMc",
        "colab_type": "text"
      },
      "source": [
        "## Train and evaluate the model\n",
        "\n",
        "After our CNN has been built, we can start training and evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xq4buwAuHOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training the model\n",
        "history_cnn = model_cnn.fit(x = train_images, y = train_labels, epochs=EPOCHS, validation_split=.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxp-ptEdnbzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_plot(history_cnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVEA1GgjuXTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = model_cnn.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS7ho0CU93K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(ff_img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25MBT3FsD--P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reshape for CNN input\n",
        "ff_img = ff_img.reshape((7, 28, 28, 1))\n",
        "print(ff_img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8Z19wAiEkvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict the classes for all custom images\n",
        "predictions_cnn = model_cnn.predict(ff_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N87gbuZ8FIsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rereshape to plot data\n",
        "ff_img = ff_img.reshape((7, 28, 28))\n",
        "print(ff_img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc_K-3cHEUOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot all predicted images with their class names\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(len(img_list)):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(ff_img[i], cmap=plt.cm.binary)\n",
        "    plt.title(class_names[np.argmax(predictions_cnn[i])])\n",
        "    plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLu3GrxEdPYF",
        "colab_type": "text"
      },
      "source": [
        "#Save and reload the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB0-p8CFdFNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(filepath='../cnn_model.h5', save_format='h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnqidfrRdcqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = tf.keras.models.load_model('../cnn_model.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B-5Og1wdnpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}